{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88478048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb8543a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Tony\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "#stemmer.stem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a3fa19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eddd416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_list(f, delim=\"<|>\"):\n",
    "    with open(f,'r',encoding='utf-8') as f:\n",
    "        d={}\n",
    "        while True:\n",
    "            try:\n",
    "                line = f.readline()\n",
    "                line = str(line).split(delim)\n",
    "                d[str(line[0])]=int(str(line[1]).replace('\\n',''))\n",
    "            except:\n",
    "                break\n",
    "    f.close()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaaed3c",
   "metadata": {},
   "source": [
    "# Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff5db73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#words\n",
    "word_emb = {}\n",
    "word_emb[\"PAD\"]=0\n",
    "word_emb[\"UNK\"]=1\n",
    "idx=2\n",
    "with open(\"Listing_Titles.tsv\", 'r+', encoding='utf-8') as f:\n",
    "\n",
    "    for i in range(0,30001):\n",
    "        line = f.readline()\n",
    "        line = line.split()\n",
    "        \n",
    "        for w in line:\n",
    "            #w = w.lower()\n",
    "            #stem = stemmer.stem(w)\n",
    "            #if not stem in word_emb.keys():\n",
    "            if not w in word_emb.keys():\n",
    "                word_emb[w]=idx\n",
    "                idx+=1\n",
    "                \n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c055da3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_words.txt\", 'w', encoding='utf-8') as f:\n",
    "    for k, v in word_emb.items():\n",
    "        f.write(str(k)+\"<|>\"+str(v)+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db16c030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53044"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f654d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"qset_lower_emb.txt\", 'w', encoding='utf-8') as f:\n",
    "    for k, v in word_emb.items():\n",
    "        f.write(str(k)+\"<|>\"+str(v)+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69efc0c",
   "metadata": {},
   "source": [
    "# BiGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb97a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BiGrams\n",
    "grams2idx={}\n",
    "idx=2\n",
    "grams2idx['PAD']=0\n",
    "grams2idx['UNK']=1\n",
    "with open(\"Listing_Titles.tsv\", 'r+', encoding='utf-8') as f:\n",
    "    f.readline()\n",
    "    for i in range(0,30001):\n",
    "        line = f.readline()\n",
    "        line = line.split()\n",
    "        \n",
    "        for i in range(0, len(line)-1):\n",
    "            gram = str(line[i]).lower()+\" \"+str(line[i+1]).lower()\n",
    "            if gram not in grams2idx.keys():\n",
    "                grams2idx[gram]=idx\n",
    "                idx+=1\n",
    "                \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ce9080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model_3_grams.txt\", 'w', encoding='utf-8') as f:\n",
    "    for k, v in grams2idx.items():\n",
    "        f.write(str(k)+\"<|>\"+str(v)+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3715fa85",
   "metadata": {},
   "source": [
    "# Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fcc0de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_emb={}\n",
    "char_emb['PAD']=0\n",
    "char_emb['UNK']=1\n",
    "idx=2\n",
    "with open(\"Listing_Titles.tsv\", 'r+', encoding='utf-8') as f:\n",
    "    for i in range(0,30001):\n",
    "        line = f.readline()\n",
    "        for l in line:\n",
    "            if not l==\"\\n\":\n",
    "                if not l in char_emb.keys():\n",
    "                    char_emb[l]=idx\n",
    "                    idx+=1\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f641fb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAD 0\n",
      "UNK 1\n",
      "R 2\n",
      "e 3\n",
      "c 4\n",
      "o 5\n",
      "r 6\n",
      "d 7\n",
      "  8\n",
      "N 9\n",
      "u 10\n",
      "m 11\n",
      "b 12\n",
      "\t 13\n",
      "T 14\n",
      "i 15\n",
      "t 16\n",
      "l 17\n",
      "1 18\n",
      "L 19\n",
      "O 20\n",
      "U 21\n",
      "I 22\n",
      "S 23\n",
      "V 24\n",
      "M 25\n",
      "4 26\n",
      "0 27\n",
      "9 28\n",
      "6 29\n",
      "H 30\n",
      "a 31\n",
      "n 32\n",
      "g 33\n",
      "P 34\n",
      "s 35\n",
      "- 36\n",
      "v 37\n",
      "2 38\n",
      "D 39\n",
      "w 40\n",
      "h 41\n",
      "B 42\n",
      "3 43\n",
      "A 44\n",
      "z 45\n",
      "p 46\n",
      "5 47\n",
      "y 48\n",
      "G 49\n",
      "C 50\n",
      "W 51\n",
      "f 52\n",
      "k 53\n",
      "F 54\n",
      "J 55\n",
      "8 56\n",
      "7 57\n",
      "Y 58\n",
      "E 59\n",
      "\" 60\n",
      ", 61\n",
      "+ 62\n",
      "x 63\n",
      "Z 64\n",
      "Q 65\n",
      "' 66\n",
      "j 67\n",
      "& 68\n",
      "q 69\n",
      "K 70\n",
      "X 71\n",
      "/ 72\n",
      "; 73\n",
      ". 74\n",
      "$ 75\n",
      "* 76\n",
      "( 77\n",
      "% 78\n",
      "! 79\n",
      "# 80\n",
      ") 81\n",
      ": 82\n",
      "‑ 83\n",
      "~ 84\n",
      "é 85\n",
      "❤ 86\n",
      "è 87\n",
      "? 88\n",
      "✨ 89\n",
      "[ 90\n",
      "] 91\n",
      "・ 92\n",
      "_ 93\n",
      "☝ 94\n",
      "✅ 95\n",
      "| 96\n",
      "É 97\n",
      "芬 98\n",
      "迪 99\n",
      "Â 100\n",
      "· 101\n",
      "⭐ 102\n",
      "’ 103\n",
      "á 104\n",
      "… 105\n",
      "С 106\n",
      "у 107\n",
      "м 108\n",
      "к 109\n",
      "а 110\n",
      "Ö 111\n",
      "Ä 112\n",
      "♡ 113\n",
      "£ 114\n",
      "€ 115\n",
      "ß 116\n",
      "✧ 117\n",
      "{ 118\n",
      "} 119\n",
      "× 120\n",
      "â 121\n",
      "™ 122\n",
      "° 123\n",
      "✿ 124\n",
      "• 125\n",
      "@ 126\n",
      "х 127\n",
      "® 128\n",
      "☆ 129\n",
      "（ 130\n",
      "） 131\n",
      "À 132\n",
      "ü 133\n",
      "□ 134\n",
      "黑 135\n",
      "花 136\n",
      "晚 137\n",
      "宴 138\n",
      "包 139\n",
      "\\ 140\n",
      "❈ 141\n",
      "ä 142\n",
      "^ 143\n",
      "ｘ 144\n",
      "ｍ 145\n",
      "ö 146\n",
      "ジ 147\n",
      "ミ 148\n",
      "ー 149\n",
      "チ 150\n",
      "ュ 151\n",
      "ウ 152\n",
      "メ 153\n",
      "ン 154\n",
      "ズ 155\n",
      "レ 156\n",
      "ザ 157\n",
      "ク 158\n",
      "ラ 159\n",
      "ッ 160\n",
      "♪ 161\n",
      "< 162\n",
      "> 163\n",
      "¹ 164\n",
      "È 165\n",
      "◆ 166\n",
      "✤ 167\n",
      "à 168\n",
      "➻ 169\n",
      "в 170\n",
      "о 171\n",
      "с 172\n",
      "ь 173\n",
      "│ 174\n",
      "❣ 175\n",
      "= 176\n",
      "❇ 177\n",
      "⍢ 178\n",
      "í 179\n",
      "！ 180\n",
      "✦ 181\n",
      "✩ 182\n",
      "✰ 183\n",
      "✪ 184\n",
      "✼ 185\n",
      "⑧ 186\n",
      "➰ 187\n",
      "☀ 188\n",
      "ı 189\n",
      "❁ 190\n",
      "ポ 191\n",
      "， 192\n",
      "、 193\n",
      "ñ 194\n",
      "ó 195\n",
      "⑤ 196\n",
      "➥ 197\n",
      "↑ 198\n",
      "′ 199\n",
      "■ 200\n",
      "Ç 201\n",
      "″ 202\n",
      "⚡ 203\n",
      "ô 204\n",
      "☘ 205\n",
      "№ 206\n",
      "♛ 207\n",
      "※ 208\n",
      "▪ 209\n",
      "Ｈ 210\n",
      "¨ 211\n",
      "§ 212\n",
      "Ë 213\n",
      "³ 214\n",
      "† 215\n",
      "ï 216\n",
      "¿ 217\n",
      "Ã 218\n",
      "© 219\n",
      "￡ 220\n",
      "⬜ 221\n"
     ]
    }
   ],
   "source": [
    "for k,v in char_emb.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d6efe9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b8cb789",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_chars.txt\", 'w', encoding='utf-8') as f:\n",
    "    for k, v in char_emb.items():\n",
    "        f.write(str(k)+\"<|>\"+str(v)+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deefc294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_emb={}\n",
    "# char_emb['PAD']=0\n",
    "# char_emb['UNK']=1\n",
    "# with open(\"Listing_Titles.tsv\", 'r+', encoding='utf-8') as f:\n",
    "#     for i in range(0,30001):\n",
    "#         line = f.readline()\n",
    "#         for l in line:\n",
    "#             if not l in trainchars:\n",
    "#                 trainchars.append(l)\n",
    "#     allchars.extend(trainchars)\n",
    "#     while True:\n",
    "#         try:\n",
    "#             line = f.readline()\n",
    "#             for l in line:\n",
    "#                 if not l in allchars:\n",
    "#                     allchars.append(l)\n",
    "#         except:\n",
    "#             break\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04eb05b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"allchars.txt\",\"w\", encoding='utf-8') as f:\n",
    "#     for char in allchars:\n",
    "#         f.write(char + \"\\n\")\n",
    "# f.close()\n",
    "# with open(\"trainchars.txt\",\"w\",encoding='utf-8') as f:\n",
    "#     for char in trainchars:\n",
    "#         f.write(char+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
