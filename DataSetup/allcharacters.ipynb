{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88478048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb8543a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Tony\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "#stemmer.stem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a3fa19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd2d2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainchars=[]\n",
    "allchars=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eddd416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_list(f, delim=\"<|>\"):\n",
    "    with open(f,'r',encoding='utf-8') as f:\n",
    "        d={}\n",
    "        while True:\n",
    "            try:\n",
    "                line = f.readline()\n",
    "                line = str(line).split(delim)\n",
    "                d[str(line[0])]=int(str(line[1]).replace('\\n',''))\n",
    "            except:\n",
    "                break\n",
    "    f.close()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaaed3c",
   "metadata": {},
   "source": [
    "# Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc748e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = get_model_list(\"model_1_tkns.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c362feff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8954"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66b33d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1947d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tstr =\"This is a TeSt positively maddening\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c378b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a test positively maddening'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tstr.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec24c58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'posit'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"positively\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393617e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff5db73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#words\n",
    "word_emb = {}\n",
    "word_emb[\"PAD\"]=0\n",
    "word_emb[\"UNK\"]=1\n",
    "idx=2\n",
    "with open(\"Listing_Titles.tsv\", 'r+', encoding='utf-8') as f:\n",
    "\n",
    "    for i in range(0,30001):\n",
    "        line = f.readline()\n",
    "        line = line.split()\n",
    "        \n",
    "        for w in line:\n",
    "            #w = w.lower()\n",
    "            #stem = stemmer.stem(w)\n",
    "            #if not stem in word_emb.keys():\n",
    "            if not w in word_emb.keys():\n",
    "                word_emb[w]=idx\n",
    "                idx+=1\n",
    "                \n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36be2aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [t for t in word_emb.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "581c5879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59366"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "306e3cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_emb['Priscilla']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c055da3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_words.txt\", 'w', encoding='utf-8') as f:\n",
    "    for k, v in word_emb.items():\n",
    "        f.write(str(k)+\"<|>\"+str(v)+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5b20b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_layer = keras.layers.StringLookup(vocabulary=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b356cc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = tf.strings.lower(\"THIS IS A TEST GUCCI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1fe9cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'this is a test gucci'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "416d2a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_layer(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db16c030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53044"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f654d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"qset_lower_emb.txt\", 'w', encoding='utf-8') as f:\n",
    "    for k, v in word_emb.items():\n",
    "        f.write(str(k)+\"<|>\"+str(v)+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69efc0c",
   "metadata": {},
   "source": [
    "# BiGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb97a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BiGrams\n",
    "grams2idx={}\n",
    "idx=2\n",
    "grams2idx['PAD']=0\n",
    "grams2idx['UNK']=1\n",
    "with open(\"Listing_Titles.tsv\", 'r+', encoding='utf-8') as f:\n",
    "    f.readline()\n",
    "    for i in range(0,30001):\n",
    "        line = f.readline()\n",
    "        line = line.split()\n",
    "        \n",
    "        for i in range(0, len(line)-1):\n",
    "            gram = str(line[i]).lower()+\" \"+str(line[i+1]).lower()\n",
    "            if gram not in grams2idx.keys():\n",
    "                grams2idx[gram]=idx\n",
    "                idx+=1\n",
    "                \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "785a547d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'louis vuitton'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(grams2idx.keys())[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ce9080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model_3_grams.txt\", 'w', encoding='utf-8') as f:\n",
    "    for k, v in grams2idx.items():\n",
    "        f.write(str(k)+\"<|>\"+str(v)+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb0dfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3715fa85",
   "metadata": {},
   "source": [
    "# Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fe75e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_emb={}\n",
    "char_emb['PAD']=0\n",
    "char_emb['UNK']=1\n",
    "with open(\"Listing_Titles.tsv\", 'r+', encoding='utf-8') as f:\n",
    "    for i in range(0,30001):\n",
    "        line = f.readline()\n",
    "        for l in line:\n",
    "            if not l in trainchars:\n",
    "                trainchars.append(l)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deefc294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_emb={}\n",
    "# char_emb['PAD']=0\n",
    "# char_emb['UNK']=1\n",
    "# with open(\"Listing_Titles.tsv\", 'r+', encoding='utf-8') as f:\n",
    "#     for i in range(0,30001):\n",
    "#         line = f.readline()\n",
    "#         for l in line:\n",
    "#             if not l in trainchars:\n",
    "#                 trainchars.append(l)\n",
    "#     allchars.extend(trainchars)\n",
    "#     while True:\n",
    "#         try:\n",
    "#             line = f.readline()\n",
    "#             for l in line:\n",
    "#                 if not l in allchars:\n",
    "#                     allchars.append(l)\n",
    "#         except:\n",
    "#             break\n",
    "# f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd599948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2533"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allchars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04eb05b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"allchars.txt\",\"w\", encoding='utf-8') as f:\n",
    "    for char in allchars:\n",
    "        f.write(char + \"\\n\")\n",
    "f.close()\n",
    "with open(\"trainchars.txt\",\"w\",encoding='utf-8') as f:\n",
    "    for char in trainchars:\n",
    "        f.write(char+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc7fc2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainchars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dead5b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R',\n",
       " 'e',\n",
       " 'c',\n",
       " 'o',\n",
       " 'r',\n",
       " 'd',\n",
       " ' ',\n",
       " 'N',\n",
       " 'u',\n",
       " 'm',\n",
       " 'b',\n",
       " '\\t',\n",
       " 'T',\n",
       " 'i',\n",
       " 't',\n",
       " 'l',\n",
       " '\\n',\n",
       " '1',\n",
       " 'L',\n",
       " 'O',\n",
       " 'U',\n",
       " 'I',\n",
       " 'S',\n",
       " 'V',\n",
       " 'M',\n",
       " '4',\n",
       " '0',\n",
       " '9',\n",
       " '6',\n",
       " 'H',\n",
       " 'a',\n",
       " 'n',\n",
       " 'g',\n",
       " 'P',\n",
       " 's',\n",
       " '-',\n",
       " 'v',\n",
       " '2',\n",
       " 'D',\n",
       " 'w',\n",
       " 'h',\n",
       " 'B',\n",
       " '3',\n",
       " 'A',\n",
       " 'z',\n",
       " 'p',\n",
       " '5',\n",
       " 'y',\n",
       " 'G',\n",
       " 'C',\n",
       " 'W',\n",
       " 'f',\n",
       " 'k',\n",
       " 'F',\n",
       " 'J',\n",
       " '8',\n",
       " '7',\n",
       " 'Y',\n",
       " 'E',\n",
       " '\"',\n",
       " ',',\n",
       " '+',\n",
       " 'x',\n",
       " 'Z',\n",
       " 'Q',\n",
       " \"'\",\n",
       " 'j',\n",
       " '&',\n",
       " 'q',\n",
       " 'K',\n",
       " 'X',\n",
       " '/',\n",
       " ';',\n",
       " '.',\n",
       " '$',\n",
       " '*',\n",
       " '(',\n",
       " '%',\n",
       " '!',\n",
       " '#',\n",
       " ')',\n",
       " ':',\n",
       " '‑',\n",
       " '~',\n",
       " 'é',\n",
       " '❤',\n",
       " 'è',\n",
       " '?',\n",
       " '✨',\n",
       " '[',\n",
       " ']',\n",
       " '・',\n",
       " '_',\n",
       " '☝',\n",
       " '✅',\n",
       " '|',\n",
       " 'É',\n",
       " '芬',\n",
       " '迪',\n",
       " 'Â',\n",
       " '·',\n",
       " '⭐',\n",
       " '’',\n",
       " 'á',\n",
       " '…',\n",
       " 'С',\n",
       " 'у',\n",
       " 'м',\n",
       " 'к',\n",
       " 'а',\n",
       " 'Ö',\n",
       " 'Ä',\n",
       " '♡',\n",
       " '£',\n",
       " '€',\n",
       " 'ß',\n",
       " '✧',\n",
       " '{',\n",
       " '}',\n",
       " '×',\n",
       " 'â',\n",
       " '™',\n",
       " '°',\n",
       " '✿',\n",
       " '•',\n",
       " '@',\n",
       " 'х',\n",
       " '®',\n",
       " '☆',\n",
       " '（',\n",
       " '）',\n",
       " 'À',\n",
       " 'ü',\n",
       " '□',\n",
       " '黑',\n",
       " '花',\n",
       " '晚',\n",
       " '宴',\n",
       " '包',\n",
       " '\\\\',\n",
       " '❈',\n",
       " 'ä',\n",
       " '^',\n",
       " 'ｘ',\n",
       " 'ｍ',\n",
       " 'ö',\n",
       " 'ジ',\n",
       " 'ミ',\n",
       " 'ー',\n",
       " 'チ',\n",
       " 'ュ',\n",
       " 'ウ',\n",
       " 'メ',\n",
       " 'ン',\n",
       " 'ズ',\n",
       " 'レ',\n",
       " 'ザ',\n",
       " 'ク',\n",
       " 'ラ',\n",
       " 'ッ',\n",
       " '♪',\n",
       " '<',\n",
       " '>',\n",
       " '¹',\n",
       " 'È',\n",
       " '◆',\n",
       " '✤',\n",
       " 'à',\n",
       " '➻',\n",
       " 'в',\n",
       " 'о',\n",
       " 'с',\n",
       " 'ь',\n",
       " '│',\n",
       " '❣',\n",
       " '=',\n",
       " '❇',\n",
       " '⍢',\n",
       " 'í',\n",
       " '！',\n",
       " '✦',\n",
       " '✩',\n",
       " '✰',\n",
       " '✪',\n",
       " '✼',\n",
       " '⑧',\n",
       " '➰',\n",
       " '☀',\n",
       " 'ı',\n",
       " '❁',\n",
       " 'ポ',\n",
       " '，',\n",
       " '、',\n",
       " 'ñ',\n",
       " 'ó',\n",
       " '⑤',\n",
       " '➥',\n",
       " '↑',\n",
       " '′',\n",
       " '■',\n",
       " 'Ç',\n",
       " '″',\n",
       " '⚡',\n",
       " 'ô',\n",
       " '☘',\n",
       " '№',\n",
       " '♛',\n",
       " '※',\n",
       " '▪',\n",
       " 'Ｈ',\n",
       " '¨',\n",
       " '§',\n",
       " 'Ë',\n",
       " '³',\n",
       " '†',\n",
       " 'ï',\n",
       " '¿',\n",
       " 'Ã',\n",
       " '©',\n",
       " '￡',\n",
       " '⬜',\n",
       " '❆',\n",
       " '❉',\n",
       " '❊',\n",
       " '①',\n",
       " '❌',\n",
       " '⚘',\n",
       " 'ë',\n",
       " '☃',\n",
       " '❀',\n",
       " 'Ｆ',\n",
       " '✮',\n",
       " '✭',\n",
       " 'î',\n",
       " '✾',\n",
       " 'Ü',\n",
       " '´',\n",
       " 'œ',\n",
       " 'ã',\n",
       " '⚪',\n",
       " '❎',\n",
       " '�',\n",
       " 'Ø',\n",
       " 'ㅐ',\n",
       " '義',\n",
       " '大',\n",
       " '利',\n",
       " '鴕',\n",
       " '鳥',\n",
       " '皮',\n",
       " '手',\n",
       " '袋',\n",
       " '▶',\n",
       " 'Á',\n",
       " 'å',\n",
       " 'ª',\n",
       " 'ç',\n",
       " '²',\n",
       " 'ж',\n",
       " 'е',\n",
       " 'н',\n",
       " 'я',\n",
       " '♻',\n",
       " 'Ж',\n",
       " '¦',\n",
       " '¡',\n",
       " '❥',\n",
       " '▲',\n",
       " 'Í',\n",
       " 'ð',\n",
       " '◇',\n",
       " '⛳',\n",
       " 'Ì',\n",
       " 'ト',\n",
       " 'バ',\n",
       " 'グ',\n",
       " '◁',\n",
       " 'ú',\n",
       " 'Ó',\n",
       " '❄',\n",
       " '☪',\n",
       " '”',\n",
       " '✔',\n",
       " '◎',\n",
       " '◼',\n",
       " 'Ñ',\n",
       " 'š',\n",
       " '✬',\n",
       " '❗',\n",
       " '路',\n",
       " '易',\n",
       " '威',\n",
       " '登',\n",
       " '装',\n",
       " '盒',\n",
       " '中',\n",
       " '小',\n",
       " '号',\n",
       " 'р',\n",
       " 'ю',\n",
       " 'з',\n",
       " '✗',\n",
       " 'М',\n",
       " 'д',\n",
       " 'и',\n",
       " 'ч',\n",
       " '●',\n",
       " '⏰',\n",
       " 'т',\n",
       " 'й',\n",
       " '紺',\n",
       " 'Ô',\n",
       " '✞',\n",
       " 'ニ',\n",
       " 'ì',\n",
       " 'ƒ',\n",
       " 'µ',\n",
       " '◯',\n",
       " '√',\n",
       " '☮',\n",
       " 'ღ',\n",
       " 'ブ',\n",
       " 'リ',\n",
       " 'フ',\n",
       " 'ケ',\n",
       " 'ス',\n",
       " 'ビ',\n",
       " 'ネ',\n",
       " '✲',\n",
       " 'л',\n",
       " 'ф',\n",
       " 'б',\n",
       " 'г',\n",
       " '✡',\n",
       " '“',\n",
       " 'ś',\n",
       " 'ł',\n",
       " '。',\n",
       " '☑',\n",
       " '`',\n",
       " '‖',\n",
       " 'ш',\n",
       " 'ね',\n",
       " 'こ',\n",
       " 'あ',\n",
       " 'つ',\n",
       " 'め',\n",
       " '✈',\n",
       " '☸',\n",
       " '✸',\n",
       " 'ŕ',\n",
       " 'Ｍ',\n",
       " 'Ž',\n",
       " '新',\n",
       " '款',\n",
       " '女',\n",
       " '防',\n",
       " '水',\n",
       " '尼',\n",
       " '龙',\n",
       " '布',\n",
       " '单',\n",
       " '肩',\n",
       " '斜',\n",
       " '挎',\n",
       " '休',\n",
       " '闲',\n",
       " '轻',\n",
       " '便',\n",
       " '妈',\n",
       " '咪',\n",
       " '旅',\n",
       " '行',\n",
       " 'μ',\n",
       " '｜',\n",
       " '¸',\n",
       " 'Б',\n",
       " 'Н',\n",
       " 'П',\n",
       " 'И',\n",
       " 'К',\n",
       " 'Ч',\n",
       " 'щ',\n",
       " '打',\n",
       " '印',\n",
       " '品',\n",
       " '牌',\n",
       " '学',\n",
       " '校',\n",
       " '青',\n",
       " '少',\n",
       " '年',\n",
       " '背',\n",
       " '童',\n",
       " '时',\n",
       " '尚',\n",
       " '士',\n",
       " '¤',\n",
       " 'Ĺ',\n",
       " '❅',\n",
       " '：',\n",
       " '⋆',\n",
       " '⁰',\n",
       " 'ُ',\n",
       " '❍',\n",
       " '∴',\n",
       " 'Ģ',\n",
       " '☂',\n",
       " 'Ｎ',\n",
       " '‰',\n",
       " '笳',\n",
       " '✉',\n",
       " '☠',\n",
       " '骷',\n",
       " '髅',\n",
       " '≇',\n",
       " '⬇',\n",
       " '◈',\n",
       " 'パ',\n",
       " '♧',\n",
       " '☔',\n",
       " '✖',\n",
       " 'п',\n",
       " 'Ï',\n",
       " '✱',\n",
       " '❃',\n",
       " '繡',\n",
       " '☐',\n",
       " 'Å',\n",
       " '→',\n",
       " 'コ',\n",
       " '¢',\n",
       " '¬',\n",
       " '闂',\n",
       " '備',\n",
       " '胶',\n",
       " '鍋',\n",
       " 'ㄩ',\n",
       " '崕',\n",
       " '鏌',\n",
       " '煘',\n",
       " '\\x80',\n",
       " '⊛',\n",
       " '❦',\n",
       " 'В',\n",
       " 'ы',\n",
       " 'Г',\n",
       " 'ピ',\n",
       " 'ヨ',\n",
       " 'ハ',\n",
       " 'ド',\n",
       " '℃',\n",
       " 'ń',\n",
       " 'モ',\n",
       " 'ル',\n",
       " '⊹',\n",
       " 'Ｂ',\n",
       " 'Ｇ',\n",
       " 'č',\n",
       " 'ן',\n",
       " 'מ',\n",
       " '◾',\n",
       " '˜',\n",
       " 'ｗ',\n",
       " 'Т',\n",
       " '⏳',\n",
       " '‡',\n",
       " 'ŵ',\n",
       " 'ㅡ',\n",
       " '巴',\n",
       " '宝',\n",
       " '莉',\n",
       " '码',\n",
       " '⛴',\n",
       " '⚓',\n",
       " '☕',\n",
       " '白',\n",
       " '☁',\n",
       " '✳',\n",
       " '▽',\n",
       " '毛',\n",
       " '毡',\n",
       " '提',\n",
       " '婴',\n",
       " '儿',\n",
       " '尿',\n",
       " '湿',\n",
       " '收',\n",
       " '纳',\n",
       " '折',\n",
       " '叠',\n",
       " '拆',\n",
       " '篮',\n",
       " '化',\n",
       " '妆',\n",
       " '整',\n",
       " '理',\n",
       " '✚',\n",
       " '⚾',\n",
       " '♚',\n",
       " 'İ',\n",
       " 'Ｅ',\n",
       " 'Ｔ',\n",
       " 'ｏ',\n",
       " 'ｔ',\n",
       " 'ｅ',\n",
       " 'ø',\n",
       " '☄',\n",
       " 'º',\n",
       " '✛',\n",
       " '最',\n",
       " '家',\n",
       " '◙',\n",
       " '◍',\n",
       " '⋒',\n",
       " '美',\n",
       " 'ヒ',\n",
       " 'ロ',\n",
       " 'Ξ',\n",
       " '≈',\n",
       " '巾',\n",
       " '着',\n",
       " '雷',\n",
       " '外',\n",
       " '拉',\n",
       " '鍊',\n",
       " '拿',\n",
       " '雕',\n",
       " '長',\n",
       " '夾',\n",
       " '⬛',\n",
       " '⚠',\n",
       " '市',\n",
       " 'ò',\n",
       " 'ڿ',\n",
       " 'ڰ',\n",
       " 'ۣ',\n",
       " '\\x81',\n",
       " 'ک',\n",
       " 'ی',\n",
       " 'ف',\n",
       " 'خ',\n",
       " 'ر',\n",
       " 'د',\n",
       " 'ط',\n",
       " 'ا',\n",
       " 'س',\n",
       " 'ê',\n",
       " '¥',\n",
       " '∷',\n",
       " '繝',\n",
       " 'ｼ',\n",
       " '━',\n",
       " '☞',\n",
       " 'ˆ',\n",
       " '籠',\n",
       " 'Σ',\n",
       " 'α',\n",
       " 'κ',\n",
       " 'ί',\n",
       " 'δ',\n",
       " 'ι',\n",
       " 'ο',\n",
       " 'Π',\n",
       " 'λ',\n",
       " 'ά',\n",
       " 'τ',\n",
       " 'η',\n",
       " 'ς',\n",
       " '⛓',\n",
       " '✯',\n",
       " 'Е',\n",
       " 'Ш',\n",
       " 'О',\n",
       " '表',\n",
       " '記',\n",
       " '無',\n",
       " 'し',\n",
       " '⁂',\n",
       " 'Ê',\n",
       " '⌚',\n",
       " '梵',\n",
       " '姿',\n",
       " '丿',\n",
       " 'Ú',\n",
       " 'Я',\n",
       " 'Ý',\n",
       " '✻',\n",
       " 'ิ',\n",
       " 'ฺ',\n",
       " '∞',\n",
       " '＆',\n",
       " '❂',\n",
       " '初',\n",
       " '音',\n",
       " '̶',\n",
       " 'õ',\n",
       " '増',\n",
       " '田',\n",
       " '飛',\n",
       " '♤',\n",
       " '♯',\n",
       " 'ē',\n",
       " '☬',\n",
       " '✴',\n",
       " '✵',\n",
       " '超',\n",
       " 'Õ',\n",
       " '⊗',\n",
       " 'ę',\n",
       " '％',\n",
       " '≛',\n",
       " 'ӓ',\n",
       " '✕',\n",
       " '～',\n",
       " 'マ',\n",
       " 'シ',\n",
       " 'ョ',\n",
       " 'ダ',\n",
       " 'イ',\n",
       " '́',\n",
       " 'ヴ',\n",
       " 'ィ',\n",
       " 'ノ',\n",
       " 'ム',\n",
       " '✺',\n",
       " '傘',\n",
       " '店',\n",
       " '█',\n",
       " 'Ù',\n",
       " 'Β',\n",
       " '森',\n",
       " '英',\n",
       " '恵',\n",
       " 'ù',\n",
       " 'Ē',\n",
       " 'ц',\n",
       " '☵',\n",
       " '♬',\n",
       " '✌',\n",
       " '⁸',\n",
       " 'ஐ',\n",
       " 'Ƹ',\n",
       " '̵',\n",
       " '̡',\n",
       " 'Ӝ',\n",
       " '̨',\n",
       " '̄',\n",
       " 'Ʒ',\n",
       " 'エ',\n",
       " 'ゼ',\n",
       " 'テ',\n",
       " '⛱',\n",
       " 'ᴖ',\n",
       " 'ᴥ',\n",
       " 'ｇ',\n",
       " '≫',\n",
       " '测',\n",
       " '试',\n",
       " '用',\n",
       " '的',\n",
       " '数',\n",
       " '据',\n",
       " '请',\n",
       " '勿',\n",
       " '修',\n",
       " '改',\n",
       " '或',\n",
       " '删',\n",
       " '除',\n",
       " '［',\n",
       " '］',\n",
       " '̀',\n",
       " '➽',\n",
       " '\\x85',\n",
       " '‐',\n",
       " 'Ъ',\n",
       " '├',\n",
       " '┩',\n",
       " 'У',\n",
       " 'А',\n",
       " 'Р',\n",
       " 'Л',\n",
       " 'Й',\n",
       " '≡',\n",
       " '☢',\n",
       " '⚰',\n",
       " '⚜',\n",
       " '沖',\n",
       " '縄',\n",
       " '琉',\n",
       " '球',\n",
       " '帆',\n",
       " '⚫',\n",
       " '▐',\n",
       " '⛄',\n",
       " '✹',\n",
       " '⇝',\n",
       " 'æ',\n",
       " '２',\n",
       " 'ﾃ',\n",
       " 'ｧ',\n",
       " 'Ⓡ',\n",
       " 'キ',\n",
       " 'ャ',\n",
       " 'オ',\n",
       " 'ū',\n",
       " '⭕',\n",
       " 'Ｄ',\n",
       " 'Ａ',\n",
       " 'Ｋ',\n",
       " 'Ｒ',\n",
       " 'Ｃ',\n",
       " 'ｎ',\n",
       " 'ｄ',\n",
       " 'ｓ',\n",
       " 'ａ',\n",
       " 'ｌ',\n",
       " 'ｉ',\n",
       " 'ｃ',\n",
       " 'ｂ',\n",
       " '¯',\n",
       " '≄',\n",
       " 'ゃ',\n",
       " 'Ł',\n",
       " 'Ｗ',\n",
       " 'Ｙ',\n",
       " '✜',\n",
       " 'ō',\n",
       " '３',\n",
       " '５',\n",
       " '７',\n",
       " '⛅',\n",
       " '性',\n",
       " 'の',\n",
       " '裝',\n",
       " '✣',\n",
       " '♫',\n",
       " '桶',\n",
       " '型',\n",
       " '丨',\n",
       " 'ア',\n",
       " 'ェ',\n",
       " '✷',\n",
       " '±',\n",
       " 'ｐ',\n",
       " '‘',\n",
       " 'Ỵ',\n",
       " '＋',\n",
       " 'Æ',\n",
       " 'ĺ',\n",
       " 'ꊛ',\n",
       " 'ϕ',\n",
       " '↔',\n",
       " '♢',\n",
       " '阿',\n",
       " '耐',\n",
       " '洛',\n",
       " 'Ā',\n",
       " 'ح',\n",
       " 'ق',\n",
       " 'ي',\n",
       " 'ب',\n",
       " 'ة',\n",
       " 'ع',\n",
       " 'ل',\n",
       " 'ى',\n",
       " 'ش',\n",
       " 'ك',\n",
       " 'م',\n",
       " 'غ',\n",
       " 'ن',\n",
       " '➖',\n",
       " '➕',\n",
       " '⓷',\n",
       " 'ソ',\n",
       " 'ナ',\n",
       " 'ቀ',\n",
       " 'በ',\n",
       " 'ቶ',\n",
       " 'ቦ',\n",
       " 'ር',\n",
       " 'ሳ',\n",
       " '▁',\n",
       " '✥',\n",
       " 'ॐ',\n",
       " '➡',\n",
       " '･',\n",
       " '♈',\n",
       " '廃',\n",
       " '盤',\n",
       " 'ゥ',\n",
       " '旧',\n",
       " 'ď',\n",
       " '▱',\n",
       " 'セ',\n",
       " 'カ',\n",
       " '②',\n",
       " 'か',\n",
       " 'ご',\n",
       " '｛',\n",
       " '｝',\n",
       " '｡',\n",
       " 'タ',\n",
       " '③',\n",
       " 'ワ',\n",
       " '縲',\n",
       " '⑭',\n",
       " 'ぱ',\n",
       " '✢',\n",
       " '➸',\n",
       " '➁',\n",
       " '❖',\n",
       " '♨',\n",
       " '↭',\n",
       " 'ג',\n",
       " '̻',\n",
       " 'Î',\n",
       " '⛵',\n",
       " '＠',\n",
       " 'Х',\n",
       " 'ם',\n",
       " 'ý',\n",
       " '◑',\n",
       " 'Ы',\n",
       " 'プ',\n",
       " '△',\n",
       " 'ガ',\n",
       " 'ボ',\n",
       " '古',\n",
       " 'ァ',\n",
       " '✓',\n",
       " 'ホ',\n",
       " 'ギ',\n",
       " '➜',\n",
       " 'ｙ',\n",
       " '☜',\n",
       " '✶',\n",
       " '鈥',\n",
       " '檚',\n",
       " '韓',\n",
       " '國',\n",
       " '牛',\n",
       " '骨',\n",
       " '湯',\n",
       " 'Š',\n",
       " '♕',\n",
       " '➤',\n",
       " '✠',\n",
       " '々',\n",
       " '⦿',\n",
       " 'ℙ',\n",
       " 'ℝ',\n",
       " 'ℂ',\n",
       " 'Ｊ',\n",
       " '◖',\n",
       " '℅',\n",
       " '濱',\n",
       " '⌒',\n",
       " '❋',\n",
       " '⑬',\n",
       " '◻',\n",
       " 'い',\n",
       " 'わ',\n",
       " 'も',\n",
       " 'と',\n",
       " 'き',\n",
       " '℠',\n",
       " '☋',\n",
       " '⬆',\n",
       " 'ء',\n",
       " 'ص',\n",
       " 'و',\n",
       " 'ز',\n",
       " 'ه',\n",
       " 'ت',\n",
       " 'Ｌ',\n",
       " '÷',\n",
       " 'ヌ',\n",
       " '◗',\n",
       " '⇔',\n",
       " '☓',\n",
       " '魏',\n",
       " '无',\n",
       " '羡',\n",
       " '蓝',\n",
       " '忘',\n",
       " '机',\n",
       " '赤',\n",
       " '▩',\n",
       " '✫',\n",
       " '＊',\n",
       " 'ˇ',\n",
       " '์',\n",
       " '一',\n",
       " '澤',\n",
       " '伸',\n",
       " '三',\n",
       " '郎',\n",
       " '✊',\n",
       " 'Ŵ',\n",
       " 'ʚ',\n",
       " 'ɞ',\n",
       " 'ベ',\n",
       " '▦',\n",
       " 'Χ',\n",
       " 'ѕ',\n",
       " '⊰',\n",
       " '⑦',\n",
       " '◊',\n",
       " 'ć',\n",
       " 'Č',\n",
       " 'は',\n",
       " 'な',\n",
       " 'く',\n",
       " 'ん',\n",
       " '️',\n",
       " 'Ω',\n",
       " '◔',\n",
       " 'ج',\n",
       " '笆',\n",
       " 'ờ',\n",
       " 'ư',\n",
       " 'Đ',\n",
       " 'ấ',\n",
       " 'ợ',\n",
       " '☾',\n",
       " '⑫',\n",
       " '軟',\n",
       " '鉚',\n",
       " '釘',\n",
       " '容',\n",
       " '量',\n",
       " '單',\n",
       " 'サ',\n",
       " 'ᚠ',\n",
       " 'ほ',\n",
       " 'ぼ',\n",
       " '日',\n",
       " '薔',\n",
       " '薇',\n",
       " '－',\n",
       " 'Θ',\n",
       " '٨',\n",
       " 'デ',\n",
       " '工',\n",
       " '藝',\n",
       " 'ʻ',\n",
       " 'ā',\n",
       " '〻',\n",
       " '老',\n",
       " '夫',\n",
       " '子',\n",
       " 'そ',\n",
       " '他',\n",
       " 'ż',\n",
       " '信',\n",
       " '京',\n",
       " '都',\n",
       " 'ئ',\n",
       " 'た',\n",
       " 'ら',\n",
       " '細',\n",
       " '胞',\n",
       " '방',\n",
       " '탄',\n",
       " '소',\n",
       " '년',\n",
       " '단',\n",
       " '▸',\n",
       " 'į',\n",
       " '本',\n",
       " '▅',\n",
       " '東',\n",
       " '方',\n",
       " '神',\n",
       " '起',\n",
       " '機',\n",
       " '織',\n",
       " '線',\n",
       " 'ž',\n",
       " '⡱',\n",
       " '生',\n",
       " '卡',\n",
       " '通',\n",
       " '加',\n",
       " '百',\n",
       " '搭',\n",
       " '补',\n",
       " '习',\n",
       " 'ｦ',\n",
       " 'З',\n",
       " 'ひ',\n",
       " 'ო',\n",
       " 'ụ',\n",
       " 'ữ',\n",
       " 'ớ',\n",
       " 'ặ',\n",
       " 'ề',\n",
       " 'ơ',\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allchars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ee279e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df4cd8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "teststr = \"teststr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22526811",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = str(teststr.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c5923c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'teststr'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"^b'(.*)'\", t)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2e05061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R\n",
      "e\n",
      "c\n",
      "o\n",
      "r\n",
      "d\n",
      " \n",
      "N\n",
      "u\n",
      "m\n",
      "b\n",
      "\t\n",
      "T\n",
      "i\n",
      "t\n",
      "l\n",
      "\n",
      "\n",
      "1\n",
      "L\n",
      "O\n",
      "U\n",
      "I\n",
      "S\n",
      "V\n",
      "M\n",
      "4\n",
      "0\n",
      "9\n",
      "6\n",
      "H\n",
      "a\n",
      "n\n",
      "g\n",
      "P\n",
      "s\n",
      "-\n",
      "v\n",
      "2\n",
      "D\n",
      "w\n",
      "h\n",
      "B\n",
      "3\n",
      "A\n",
      "z\n",
      "p\n",
      "5\n",
      "y\n",
      "G\n",
      "C\n",
      "W\n",
      "f\n",
      "k\n",
      "F\n",
      "J\n",
      "8\n",
      "7\n",
      "Y\n",
      "E\n",
      "\"\n",
      ",\n",
      "+\n",
      "x\n",
      "Z\n",
      "Q\n",
      "'\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m c\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(c)\n\u001b[1;32m----> 4\u001b[0m     testchar \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m^b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m(.*)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mxe*\u001b[39m\u001b[38;5;124m'\u001b[39m,testchar):\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m(testchar)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for c in allchars:\n",
    "    if c!='':\n",
    "        print(c)\n",
    "        testchar = re.findall(r\"^b'(.*)'\",str(c.encode()))[0]\n",
    "        \n",
    "        if re.match(r'\\\\xe*',testchar):\n",
    "            print(testchar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d4de641",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot use a string pattern on a bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m allchars:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(c)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Fresh2022\\lib\\re.py:191\u001b[0m, in \u001b[0;36mmatch\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatch\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;124;03m\"\"\"Try to apply the pattern at the start of the string, returning\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
     ]
    }
   ],
   "source": [
    "for c in allchars:\n",
    "    if not re.match(r'\\\\x', c.encode()):\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f427b8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
